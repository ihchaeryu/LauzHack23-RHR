{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import umap\n",
    "from kneed import KneeLocator\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster, centroid\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix, classification_report, silhouette_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible fonts: DejaVuSans-Bold.ttf, DejaVuSans-BoldOblique.ttf, DejaVuSans-ExtraLight.ttf, DejaVuSans-Oblique.ttf, DejaVuSans.ttf, DejaVuSansCondensed-Bold.ttf, DejaVuSansCondensed-BoldOblique.ttf, DejaVuSansCondensed-Oblique.ttf, DejaVuSansCondensed.ttf, DejaVuSansMono-Bold.ttf, DejaVuSansMono-BoldOblique.ttf, DejaVuSansMono-Oblique.ttf, DejaVuSansMono.ttf, GillSansBoItNova.ttf, GillSansBoNova.ttf, GillSansCondBoItNova.ttf, GillSansCondBoNova.ttf, GillSansCondExtraItNova.ttf, GillSansCondExtraNova.ttf, GillSansCondItNova.ttf, GillSansCondLightItNova.ttf, GillSansCondLightNova.ttf, GillSansCondNova.ttf, GillSansCondUltraBoNova.ttf, GillSansItNova.ttf, GillSansLightItNova.ttf, GillSansLightNova.ttf, GillSansNova.ttf, GillSansUltraBoNova.ttf, SansSerifCollection.ttf, \n"
     ]
    }
   ],
   "source": [
    "url      = 'https://github.com/MaartenGr/cTFIDF/archive/refs/tags/v0.1.1.tar.gz'\n",
    "version  = re.search(r'/v(.+?)\\.tar\\.gz', url).group(1)\n",
    "dir_name = f'cTFIDF-{version}'\n",
    "dir_path = os.path.join(os.getcwd(),dir_name)\n",
    "import sys\n",
    "if sys.path[-1] != dir_path:\n",
    "    sys.path.append(dir_path)\n",
    "from ctfidf import CTFIDFVectorizer\n",
    "\n",
    "import matplotlib.font_manager\n",
    "fonts = matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "print(\"Possible fonts: \", end=\"\")\n",
    "for f in sorted(fonts):\n",
    "    if 'Narrow' in f:\n",
    "        print(f.split(os.path.sep)[-1], end=\", \")\n",
    "    elif 'Sans' in f:\n",
    "        print(f.split(os.path.sep)[-1], end=\", \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using font: C:\\Windows\\Fonts\\Candaral.ttf\n",
      "  Guessing at font name: C : \\ Windows \\ Fonts \\ Candaral .ttf\n"
     ]
    }
   ],
   "source": [
    "fp = fonts[0] #Â Ensure at least _something_ is set here\n",
    "for f in fonts:\n",
    "    if 'LiberationSansNarrow-Regular' in f:\n",
    "        fp = f.split(os.path.sep)[-1].split('.')[0]\n",
    "        break\n",
    "    elif 'Arial Narrow.ttf' in f:\n",
    "        fp = f.split(os.path.sep)[-1].split('.')[0]\n",
    "        break\n",
    "    elif 'Narrow' in f:\n",
    "        fp = f.split(os.path.sep)[-1].split('.')[0]\n",
    "print(f\"Using font: {fp}\")\n",
    "\n",
    "fname = ''.join([f' {x}' if x==x.upper() else x for x in fp.split('-')[0]]).strip().replace('  ','')\n",
    "print(f\"  Guessing at font name: {fname}\")\n",
    "\n",
    "# These are font dictionaries for the 's'uper-title, 't'itle, \n",
    "# 'a'xis, and 'l'abels.\n",
    "sfont = {'fontname':fname, 'fontsize':16}\n",
    "tfont = {'fontname':fname, 'fontsize':12}\n",
    "afont = {'fontname':fname, 'fontsize':10}\n",
    "lfont = {'fontname':fname, 'fontsize':8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "rs = 43\n",
    "\n",
    "# Which embeddings to use\n",
    "src_embeddings = 'doc_vec'  #'word_vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the file\n",
    "fn = 'Amazon_Unlocked_Mobile.csv'\n",
    "\n",
    "# See if the data has already been downloaded, and\n",
    "# if not, download it from the web site. We save a\n",
    "# copy locally so that you can run this tutorial\n",
    "# offline and also spare the host the bandwidth costs\n",
    "if os.path.exists(os.path.join('data',fn)):\n",
    "    df = pd.read_csv(os.path.join('data',fn))\n",
    "else:\n",
    "    # We will look for/create a 'data' directory\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "   \n",
    "    # Download and save\n",
    "    df = pd.read_parquet(f'http://orca.casa.ucl.ac.uk/~jreades/data/{fn}')\n",
    "    df.to_parquet(os.path.join('data',fn))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading columns: Product Name, Brand Name, Price, Rating, Reviews, Review Votes\n",
      "               Price         Rating   Review Votes\n",
      "count  407907.000000  413840.000000  401544.000000\n",
      "mean      226.867155       3.819578       1.507237\n",
      "std       273.006259       1.548216       9.163853\n",
      "min         1.730000       1.000000       0.000000\n",
      "25%        79.990000       3.000000       0.000000\n",
      "50%       144.710000       5.000000       0.000000\n",
      "75%       269.990000       5.000000       1.000000\n",
      "max      2598.000000       5.000000     645.000000\n",
      "413840\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading columns: {', '.join(df.columns.tolist())}\")\n",
    "print(df.describe())\n",
    "print(df.shape[0])\n",
    "\n",
    "df_small = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lauzHackNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
